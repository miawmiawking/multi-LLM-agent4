import requests
import streamlit as st
from langchain.tools import DuckDuckGoSearchRun
import PyPDF2
from docx import Document
import chardet
import base64
from openai import OpenAI

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
def initialize_session_state():
    state_defaults = {
        "messages": [],
        "search_enabled": False,
        "file_analyzed": False,
        "file_content": "",
        "file_summary": "",
        "selected_model": "è±†åŒ…",
        "selected_function": "æ™ºèƒ½é—®ç­”",
        "api_keys": {}
    }
    for key, value in state_defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

# é¡µé¢é…ç½®
st.set_page_config(page_title="å¤šæ¨¡å‹æ™ºèƒ½åŠ©æ‰‹", layout="wide")
initialize_session_state()

# ====================
# æ ¸å¿ƒåŠŸèƒ½å®ç°
# ====================
def call_model_api(prompt, model_type, uploaded_file=None):
    """ç»Ÿä¸€æ¨¡å‹è°ƒç”¨æ¥å£"""
    headers = {"Content-Type": "application/json"}
    params = {}

    try:
        if model_type == "DeepSeek":
            headers["Authorization"] = f"Bearer {st.session_state.api_keys['DeepSeek']}"
            response = requests.post(
                "https://api.deepseek.com/v1/chat/completions",
                json={
                    "model": "deepseek-chat",
                    "messages": [
                        {"role": "system", "content": "ä½ æ˜¯DeepSeekï¼Œç”±æ­å·æ·±åº¦æ±‚ç´¢äººå·¥æ™ºèƒ½åŸºç¡€æŠ€æœ¯ç ”ç©¶æœ‰é™å…¬å¸å¼€å‘çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œä½ æ›´æ“…é•¿ä¸­æ–‡å’Œè‹±æ–‡çš„å¯¹è¯ã€‚ä½ ä¼šä¸ºç”¨æˆ·æä¾›å®‰å…¨ï¼Œæœ‰å¸®åŠ©ï¼Œå‡†ç¡®çš„å›ç­”ã€‚åŒæ—¶ï¼Œä½ ä¼šæ‹’ç»ä¸€åˆ‡æ¶‰åŠææ€–ä¸»ä¹‰ï¼Œç§æ—æ­§è§†ï¼Œé»„è‰²æš´åŠ›ç­‰é—®é¢˜çš„å›ç­”ã€‚DeepSeekä¸ºä¸“æœ‰åè¯ï¼Œä¸å¯ç¿»è¯‘æˆå…¶ä»–è¯­è¨€ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": temperature,
                    "max_tokens": max_tokens
                },
                headers=headers
            )
            return response.json()["choices"][0]["message"]["content"]

        elif model_type == "è±†åŒ…":
            headers["Authorization"] = f"Bearer {st.session_state.api_keys['è±†åŒ…']}"
            response = requests.post(
                "https://ark.cn-beijing.volces.com/api/v3/chat/completions",
                json={
                    "model": "ep-20250128163906-p4tb5",
                    "messages": [
                        {"role": "system", "content": "You are a helpful assistant."},
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": temperature,
                    "max_tokens": max_tokens
                },
                headers=headers
            )
            try:
                response_json = response.json()
                if "choices" in response_json and len(response_json["choices"]) > 0:
                    return response_json["choices"][0]["message"]["content"]
                else:
                    st.error(f"è±†åŒ… API è¿”å›æ ¼å¼å¼‚å¸¸: {response_json}")
                    return None
            except Exception as e:
                st.error(f"è§£æè±†åŒ… API å“åº”å¤±è´¥: {str(e)}")
                return None

        elif model_type == "é€šä¹‰åƒé—®":
            headers["Authorization"] = f"Bearer {st.session_state.api_keys['é€šä¹‰åƒé—®']}"
            response = requests.post(
                "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
                json={
                    "model": "qwen-plus",
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": temperature,
                    "max_tokens": max_tokens
                },
                headers=headers
            )
            response_json = response.json()
            try:
                if "choices" in response_json and len(response_json["choices"]) > 0:
                    return response_json["choices"][0]["message"]["content"]
                else:
                    st.error(f"é€šä¹‰åƒé—® API è¿”å›æ ¼å¼å¼‚å¸¸: {response_json}")
                    return None
            except Exception as e:
                st.error(f"è§£æé€šä¹‰åƒé—® API å“åº”å¤±è´¥: {str(e)}")
                return None

        elif model_type == "æ–‡å¿ƒä¸€è¨€":
            headers["Authorization"] = f"Bearer {st.session_state.api_keys['æ–‡å¿ƒä¸€è¨€']}"
            response = requests.post(
                "https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/completions",
                json={
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": temperature,
                    "max_tokens": max_tokens
                },
                headers=headers
            )
            response_json = response.json()
            try:
                if "result" in response_json:
                    return response_json["result"]
                else:
                    st.error(f"æ–‡å¿ƒä¸€è¨€ API è¿”å›æ ¼å¼å¼‚å¸¸: {response_json}")
                    return None
            except Exception as e:
                st.error(f"è§£ææ–‡å¿ƒä¸€è¨€ API å“åº”å¤±è´¥: {str(e)}")
                return None

        elif model_type == "æ™ºè°±æ¸…è¨€":
            headers["Authorization"] = f"Bearer {st.session_state.api_keys['æ™ºè°±æ¸…è¨€']}"
            response = requests.post(
                "https://open.bigmodel.cn/api/paas/v4/chat/completions",
                json={
                    "model": "glm-4",
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": temperature,
                    "max_tokens": max_tokens
                },
                headers=headers
            )
            return response.json()["choices"][0]["message"]["content"]

        elif model_type == "MiniMax":
            headers["Authorization"] = f"Bearer {st.session_state.api_keys['MiniMax']}"
            response = requests.post(
                "https://api.minimax.chat/v1/text/chatcompletion_v2",
                json={
                    "model": "abab5.5-chat",
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": temperature,
                    "max_tokens": max_tokens
                },
                headers=headers
            )
            return response.json()["choices"][0]["message"]["content"]

        elif model_type == "Kimi(è§†è§‰ç†è§£)":
            headers["Authorization"] = f"Bearer {st.session_state.api_keys['Kimi(è§†è§‰ç†è§£)']}"
            response = requests.post(
                "https://api.moonshot.cn/v1/chat/completions",
                json={
                    "model": "moonshot-v1-8k",
                    "messages": [
                        {"role": "system", "content": "ä½ æ˜¯Kimiï¼Œç”±Moonshot AIæä¾›çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œä½ æ›´æ“…é•¿ä¸­æ–‡å’Œè‹±æ–‡çš„å¯¹è¯ã€‚ä½ ä¼šä¸ºç”¨æˆ·æä¾›å®‰å…¨ï¼Œæœ‰å¸®åŠ©ï¼Œå‡†ç¡®çš„å›ç­”ã€‚åŒæ—¶ï¼Œä½ ä¼šæ‹’ç»ä¸€åˆ‡æ¶‰åŠææ€–ä¸»ä¹‰ï¼Œç§æ—æ­§è§†ï¼Œé»„è‰²æš´åŠ›ç­‰é—®é¢˜çš„å›ç­”ã€‚Moonshot AI ä¸ºä¸“æœ‰åè¯ï¼Œä¸å¯ç¿»è¯‘æˆå…¶ä»–è¯­è¨€ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": temperature,
                    "max_tokens": max_tokens
                },
                headers=headers
            )
            return response.json()["choices"][0]["message"]["content"]

        elif model_type == "GPTs(èŠå¤©ã€è¯­éŸ³è¯†åˆ«)":
            headers["Authorization"] = f"Bearer {st.session_state.api_keys['OpenAI']}"
            try:
                response = requests.post(
                    "https://api.openai.com/v1/chat/completions",
                    json={
                        "model": "gpt-4o",
                        "messages": [{"role": "user", "content": prompt}],
                        "temperature": temperature,
                        "max_tokens": max_tokens
                    },
                    headers=headers
                )
                response_json = response.json()
                if "error" in response_json:
                    st.error(f"API è¿”å›é”™è¯¯: {response_json['error']['message']}")
                    return None
                if "choices" in response_json and len(response_json["choices"]) > 0:
                    return response_json["choices"][0]["message"]["content"]
                else:
                    st.error(f"API è¿”å›æ ¼å¼å¼‚å¸¸: {response_json}")
                    return None
            except Exception as e:
                st.error(f"API è°ƒç”¨å¤±è´¥: {str(e)}")
                return None

        elif model_type == "DALL-E(æ–‡ç”Ÿå›¾)":
            headers["Authorization"] = f"Bearer {st.session_state.api_keys['OpenAI']}"
            response = requests.post(
                "https://api.openai.com/v1/images/generations",
                json={
                    "prompt": prompt,
                    "n": 1,
                    "size": "512x512"
                },
                headers=headers
            )
            response_json = response.json()
            if "data" in response_json and len(response_json["data"]) > 0:
                image_url = response_json["data"][0]["url"]
                return image_url
            else:
                st.error(f"DALL-E API è¿”å›æ ¼å¼å¼‚å¸¸: {response_json}")
                return None

        elif model_type == "o1(æ·±åº¦æ¨ç†)":
            headers["Authorization"] = f"Bearer {st.session_state.api_keys['OpenAI']}"
            response = requests.post(
                "https://api.openai.com/v1/chat/completions",
                json={
                    "model": "o1-preview",
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": 1.0,
                    "max_completion_tokens": max_tokens  # æ›¿æ¢ä¸ºæ­£ç¡®çš„å‚æ•°
                },
                headers=headers
            )
            response_json = response.json()
            if "choices" in response_json:
                return response_json["choices"][0]["message"]["content"]
            else:
                st.error(f"o1 API è¿”å›æ ¼å¼å¼‚å¸¸: {response_json}")
                return None

    except Exception as e:
        st.error(f"APIè°ƒç”¨å¤±è´¥: {str(e)}")
        return None

def handle_file_upload(uploaded_file):
    """å¤„ç†ä¸Šä¼ æ–‡ä»¶å¹¶è¿”å›å†…å®¹"""
    file_type = uploaded_file.name.split(".")[-1].lower()
    try:
        if file_type in ["txt", "pdf", "docx"]:
            # æ–‡æœ¬ç±»æ–‡ä»¶å¤„ç†
            if file_type == "txt":
                raw_data = uploaded_file.getvalue()
                encoding = chardet.detect(raw_data)["encoding"]
                return raw_data.decode(encoding)

            elif file_type == "pdf":
                pdf_reader = PyPDF2.PdfReader(uploaded_file)
                return "\n".join([page.extract_text() for page in pdf_reader.pages])

            elif file_type == "docx":
                doc = Document(uploaded_file)
                return "\n".join([para.text for para in doc.paragraphs])

        elif file_type in ["jpg", "jpeg", "png"]:
            # å›¾ç‰‡æ–‡ä»¶ç›´æ¥è¿”å›æ–‡ä»¶å†…å®¹
            return uploaded_file.getvalue()

        elif file_type in ["mp3", "wav", "m4a", "mp4", "webm"]:  # æ”¯æŒçš„éŸ³é¢‘æ ¼å¼
            return uploaded_file

    except Exception as e:
        st.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
        return None

def perform_visual_analysis(image_content):
    """ä½¿ç”¨ moonshot-v1-8k-vision-preview æ¨¡å‹è¿›è¡Œè§†è§‰åˆ†æ"""
    try:
        # è°ƒç”¨ moonshot-v1-8k-vision-preview æ¨¡å‹è¿›è¡Œè§†è§‰åˆ†æ
        headers = {"Content-Type": "application/json", "Authorization": f"Bearer {st.session_state.api_keys['Kimi']}"}
        # å°†å›¾ç‰‡å†…å®¹è½¬æ¢ä¸ºBase64ç¼–ç 
        encoded_string = base64.b64encode(image_content).decode("utf-8")
        response = requests.post(
            "https://api.moonshot.cn/v1/chat/completions",
            json={
                "model": "moonshot-v1-8k-vision-preview",
                "messages": [
                    {"role": "user", "content": [{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{encoded_string}"}}]}
                ],
                "temperature": temperature,
                "max_tokens": max_tokens
            },
            headers=headers
        )
        response_json = response.json()
        if "choices" in response_json and len(response_json["choices"]) > 0:
            return response_json["choices"][0]["message"]["content"]
        else:
            st.error(f"moonshot-v1-8k-vision-preview API è¿”å›æ ¼å¼å¼‚å¸¸: {response_json}")
            return None
    except Exception as e:
        st.error(f"è§†è§‰åˆ†æå¤±è´¥: {str(e)}")
        return None

# ====================
# ä¾§è¾¹æ é…ç½®
# ====================
with st.sidebar:
    st.header("âš™ï¸ ç³»ç»Ÿè®¾ç½®")

    # API å¯†é’¥ç®¡ç†
    st.subheader("APIå¯†é’¥ç®¡ç†")
    api_key_input = st.text_input(
        "è¾“å…¥ API å¯†é’¥",
        help="è¾“å…¥ä¸€ä¸ªAPIå¯†é’¥ï¼Œç”¨äºè®¿é—®æ‰€é€‰æ¨¡å‹",
        type="password"
    )
    if api_key_input:
        st.session_state.api_keys = {
            "è±†åŒ…": api_key_input,
            "Kimi(è§†è§‰ç†è§£)": api_key_input,
            "DeepSeek": api_key_input,
            "é€šä¹‰åƒé—®": api_key_input,
            "æ–‡å¿ƒä¸€è¨€": api_key_input,
            "æ™ºè°±æ¸…è¨€": api_key_input,
            "MiniMax": api_key_input,
            "OpenAI": api_key_input,
        }
        st.success("API å¯†é’¥å·²ä¿å­˜ï¼")

    # æ¨¡å‹é€‰æ‹©
    model_options = {
        "è±†åŒ…": ["ep-20250128163906-p4tb5"],
        "DeepSeek": ["deepseek-chat", "deepseek-reasoner"],
        "é€šä¹‰åƒé—®": ["qwen-plus"],
        "æ–‡å¿ƒä¸€è¨€": ["ERNIE-Bot"],
        "æ™ºè°±æ¸…è¨€": ["glm-4"],
        "MiniMax": ["abab5.5-chat"],
        "DALL-E(æ–‡ç”Ÿå›¾)": ["dall-e-3"],
        "o1(æ·±åº¦æ¨ç†)": ["o1-preview"],
        "Kimi(è§†è§‰ç†è§£)": ["moonshot-v1-8k", "moonshot-v1-8k-vision-preview"],
        "GPTs(èŠå¤©ã€è¯­éŸ³è¯†åˆ«)": ["gpt-4"]
    }

    st.session_state.selected_model = st.selectbox(
        "é€‰æ‹©å¤§æ¨¡å‹",
        list(model_options.keys()),
        index=0
    )

    # åŠŸèƒ½é€‰æ‹©
    function_options = [
        "æ™ºèƒ½é—®ç­”",
        "æ–‡æœ¬ç¿»è¯‘",
        "æ–‡æœ¬æ€»ç»“",
        "æ–‡ç”Ÿå›¾",
        "æ·±åº¦æ¨ç†",
        "è§†è§‰ç†è§£",
        "è¯­éŸ³è¯†åˆ«"
    ]
    st.session_state.selected_function = st.selectbox(
        "é€‰æ‹©åŠŸèƒ½",
        function_options,
        index=0
    )

    # é€šç”¨å‚æ•°
    col1, col2 = st.columns(2)
    with col1:
        temperature = st.slider("åˆ›æ„åº¦", 0.0, 2.0, 0.7, 0.1)
    with col2:
        max_tokens = st.slider("å“åº”é•¿åº¦", 100, 2048, 1024, 100)

    # API æµ‹è¯•åŠŸèƒ½
    st.subheader("API æµ‹è¯•")
    if st.button("ğŸ” æµ‹è¯• API è¿æ¥"):
        if not st.session_state.api_keys:
            st.error("è¯·å…ˆè¾“å…¥ API å¯†é’¥ï¼")
        else:
            with st.spinner("æ­£åœ¨æµ‹è¯• API è¿æ¥..."):
                try:
                    test_prompt = "ä½ å¥½ï¼Œè¯·å›å¤'è¿æ¥æˆåŠŸ'ã€‚"
                    response = call_model_api(test_prompt, st.session_state.selected_model)
                    if response:
                        st.success(f"API è¿æ¥æˆåŠŸï¼æ¨¡å‹å›å¤ï¼š{response}")
                    else:
                        st.error("API è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥å¯†é’¥å’Œç½‘ç»œè®¾ç½®ã€‚")
                except Exception as e:
                    st.error(f"API æµ‹è¯•å¤±è´¥ï¼š{str(e)}")

    if st.button("ğŸ§¹ æ¸…ç©ºå¯¹è¯å†å²"):
        st.session_state.messages = []
        st.rerun()

# ====================
# ä¸»ç•Œé¢å¸ƒå±€
# ====================
st.title("ğŸ¤– å¤šæ¨¡å‹æ™ºèƒ½åŠ©æ‰‹")

# æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
uploaded_file = st.file_uploader(
    "ğŸ“ ä¸Šä¼ æ–‡ä»¶ï¼ˆæ”¯æŒæ–‡æœ¬/PDF/Word/å›¾ç‰‡/éŸ³é¢‘ï¼‰",
    type=["txt", "pdf", "docx", "doc", "jpg", "jpeg", "png", "mp3", "wav", "m4a", "mp4", "webm"],
    key="file_uploader"
)

# å°†ä¸Šä¼ çš„æ–‡ä»¶ä¿å­˜åˆ° session_state ä¸­
if uploaded_file:
    st.session_state.uploaded_file = uploaded_file
    st.session_state.file_content = handle_file_upload(uploaded_file)
    if st.session_state.file_content:
        st.session_state.file_analyzed = True

        # è‡ªåŠ¨æ‰§è¡Œè¯­éŸ³è¯†åˆ«åŠŸèƒ½
        if uploaded_file.name.split(".")[-1].lower() in ["mp3", "wav", "m4a", "mp4", "webm"]:
            try:
                # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
                client = OpenAI(api_key=st.session_state.api_keys["OpenAI"])
                # è°ƒç”¨ Whisper æ¨¡å‹è¿›è¡Œè¯­éŸ³è¯†åˆ«
                transcription = client.audio.transcriptions.create(
                    model="whisper-1",
                    file=st.session_state.file_content
                )
                st.write("è¯­éŸ³è¯†åˆ«ç»“æœï¼š")
                st.write(transcription.text)
                st.session_state.file_summary = transcription.text
            except Exception as e:
                st.error(f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {str(e)}")
        elif uploaded_file.name.split(".")[-1].lower() in ["jpg", "jpeg", "png"]:
            analysis_result = perform_visual_analysis(st.session_state.file_content)
            st.write("è§†è§‰åˆ†æç»“æœï¼š")
            st.write(analysis_result)
        else:
            summary_prompt = f"è¯·å¯¹ä»¥ä¸‹å†…å®¹è¿›è¡Œæ€»ç»“å’Œæ¢³ç†ï¼Œæå–æ ¸å¿ƒå†…å®¹ï¼š\n{st.session_state.file_content}"
            summary_response = call_model_api(summary_prompt, st.session_state.selected_model)
            if summary_response:
                st.session_state.file_summary = summary_response
                st.write("æ–‡ä»¶æ ¸å¿ƒå†…å®¹æ€»ç»“ï¼š")
                st.write(st.session_state.file_summary)

# åŠŸèƒ½æ“ä½œåŒº
with st.container():
    col1, col2 = st.columns([1, 1])
    with col1:
        search_toggled = st.button(
            f"ğŸŒ è”ç½‘æœç´¢ {'(on)' if st.session_state.search_enabled else '(off)'}",
            help="å¯ç”¨/ç¦ç”¨å®æ—¶ç½‘ç»œæœç´¢",
            use_container_width=True
        )
        if search_toggled:
            st.session_state.search_enabled = not st.session_state.search_enabled

# ç”¨æˆ·é—®é¢˜è¾“å…¥æ 
with st.container():
    col1, col2 = st.columns([3, 1])
    with col1:
        user_input = st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜æˆ–æŒ‡ä»¤...", key="user_input")

# åˆå§‹åŒ– DuckDuckGo æœç´¢å·¥å…·
search_tool = DuckDuckGoSearchRun()
def perform_web_search(query):
    """æ‰§è¡Œç½‘ç»œæœç´¢å¹¶è¿”å›ç»“æœ"""
    try:
        search_results = search_tool.run(query)
        return search_results
    except Exception as e:
        st.error(f"ç½‘ç»œæœç´¢å¤±è´¥: {str(e)}")
        return "æ— æ³•è·å–ç½‘ç»œæœç´¢ç»“æœ"

# ====================
# äº¤äº’å¤„ç†é€»è¾‘
# ====================
if uploaded_file:
    st.session_state.file_content = handle_file_upload(uploaded_file)
    if st.session_state.file_content:
        st.session_state.file_analyzed = True

        # è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œæ–‡ä»¶å†…å®¹çš„æ€»ç»“å’Œæ¢³ç†
        if uploaded_file.name.split(".")[-1].lower() in ["jpg", "jpeg", "png"]:
            analysis_result = perform_visual_analysis(st.session_state.file_content)
            st.write("è§†è§‰åˆ†æç»“æœï¼š")
            st.write(analysis_result)
        elif uploaded_file.name.split(".")[-1].lower() in ["mp3", "wav", "m4a", "mp4", "webm"]:  # è¯­éŸ³æ–‡ä»¶å¤„ç†
            if st.session_state.selected_function == "è¯­éŸ³è¯†åˆ«":
                try:
                    # ç›´æ¥è°ƒç”¨ Whisper æ¨¡å‹è¿›è¡Œè¯­éŸ³è¯†åˆ«
                    client = OpenAI(api_key=st.session_state.api_keys["OpenAI"])
                    transcription = client.audio.transcriptions.create(
                        model="whisper-1",
                        file=st.session_state.file_content
                    )
                    st.write("è¯­éŸ³è¯†åˆ«ç»“æœï¼š")
                    st.write(transcription.text)
                except Exception as e:
                    st.error(f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {str(e)}")
        else:
            summary_prompt = f"è¯·å¯¹ä»¥ä¸‹å†…å®¹è¿›è¡Œæ€»ç»“å’Œæ¢³ç†ï¼Œæå–æ ¸å¿ƒå†…å®¹ï¼š\n{st.session_state.file_content}"
            summary_response = call_model_api(summary_prompt, st.session_state.selected_model)
            if summary_response:
                st.session_state.file_summary = summary_response
                st.write("æ–‡ä»¶æ ¸å¿ƒå†…å®¹æ€»ç»“ï¼š")
                st.write(st.session_state.file_summary)

if user_input:
    full_prompt = f"{user_input}\n{st.session_state.file_summary}"

    with st.spinner("ğŸ§  æ­£åœ¨å¤„ç†è¯·æ±‚..."):
        # æ ¹æ®åŠŸèƒ½è·¯ç”±å¤„ç†
        if st.session_state.selected_function == "æ–‡ç”Ÿå›¾":
            image_url = call_model_api(full_prompt, "DALL-E")
            st.image(image_url, caption="ç”Ÿæˆç»“æœ")

        elif st.session_state.selected_function == "è§†è§‰ç†è§£":
            if uploaded_file and uploaded_file.name.split(".")[-1].lower() in ["jpg", "jpeg", "png"]:
                analysis_result = perform_visual_analysis(st.session_state.file_content)
                st.write("è§†è§‰åˆ†æç»“æœï¼š")
                st.write(analysis_result)
            else:
                st.error("è¯·ä¸Šä¼ å›¾ç‰‡æ–‡ä»¶è¿›è¡Œè§†è§‰ç†è§£åˆ†æã€‚")

        elif st.session_state.selected_function == "æ·±åº¦æ¨ç†":
            if st.session_state.selected_model == "o1(æ·±åº¦æ¨ç†)":
                response_text = call_model_api(full_prompt, "o1(æ·±åº¦æ¨ç†)")
                st.write(response_text)

        else:  # æ™ºèƒ½é—®ç­”/ç¿»è¯‘/æ€»ç»“
            if st.session_state.search_enabled:
                search_results = perform_web_search(user_input)
                full_prompt = f"{full_prompt}\nã€ç½‘ç»œæœç´¢ç»“æœã€‘\n{search_results}"

            response = call_model_api(full_prompt, st.session_state.selected_model)
            st.session_state.messages.append({
                "role": "assistant",
                "content": response,
                "type": "text"
            })

# ====================
# å¯¹è¯å†å²å±•ç¤º
# ====================
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        if msg.get("type") == "image":
            st.image(msg["content"])
        else:
            st.write(msg["content"])

# åˆå§‹æç¤º
if not st.session_state.messages:
    with st.chat_message("assistant"):
        st.write("æ‚¨å¥½ï¼æˆ‘æ˜¯å¤šæ¨¡å‹æ™ºèƒ½åŠ©æ‰‹ï¼Œè¯·é€‰æ‹©æ¨¡å‹å’ŒåŠŸèƒ½å¼€å§‹äº¤äº’ã€‚")